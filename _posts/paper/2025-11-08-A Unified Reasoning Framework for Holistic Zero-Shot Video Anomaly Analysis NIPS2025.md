---
layout: post
title: 'A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis NIPS2025🙁'
subtitle: '用于零样本视频异常检测的统一推理架构'
date: 2025-11-08
author: Sun
cover: 'https://pic1.imgdb.cn/item/690f1eb23203f7be00e415f2.png'
tags: 论文阅读
---

> [A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis](https://arxiv.org/pdf/2511.00962)

> 🌟🌟[项目主页](https://rathgrith.github.io/Unified_Frame_VAA/)
> 
> 📌作者单位
> 
> 1. Institute of Information Science, Beijing Jiaotong University
> 2. The MIx Group, University of Birmingham

# 1.文章针对痛点

现有的视频异常分析研究主要存在以下问题：

1. ​**缺乏完整性**​：大多数视频异常检测(*VAD* )方法只提供帧级别的异常分数，无法解释为什么某个片段是异常的，缺少空间和语义上下文信息。
2. ​**任务割裂**​：虽然近期出现了空间定位(*VAL* )和文本理解(*VAU* )等下游任务，但这些方法大多专注于某一类任务，无法提供对视频异常的整体分析。
3. ​**数据依赖性强**​：传统*VAD* 和*VAL* 模型需要时间掩码或空间边界框等标注，且异常定义在不同数据集间差异很大。一个在某个领域调优的模型往往在另一个领域失效。
4. ​**训练成本高**​：基于*MLLM* 的方法需要大量标注数据进行指令微调，且仅能识别训练时见过的异常类型。
5. ​**零样本能力有限**​：现有的严格零样本方法仅支持时序检测，缺乏空间定位和文本解释能力；而基于提示调优的方法虽然性能较好，但仍需要标注数据，且提示往往是任务/领域特定的。

# 2.主要贡献

本文提出了一个统一的零样本视频异常分析框架，具有以下主要贡献：

1. ​**统一框架**​：首次在零样本设置下统一了视频异常分析的三大任务：
   * 时序检测(*VAD* ) - 回答"何时"异常
   * 空间定位(*VAL* ) - 回答"哪里"异常
   * 文本理解*(VAU* ) - 回答"什么"和"为什么"异常
2. ​**任务内推理**​：
   * 通过初步*VAD* 提取异常先验(*anomaly priors* )和上下文标签列表
   * 使用基于分数的门控机制选择性地触发额外推理步骤
   * 仅对低置信度样本进行二次推理，避免"过度思考"导致的幻觉问题
3. ​**任务间链接**​：
   * 将VAD任务提取的时序信息和标签列表传递给下游任务
   * 动态细化VAL和VAU的提示词，提供样本特定的上下文
   * 使用分数门控的定位覆盖增强视觉提示
4. ​**零样本*SOTA* 性能**​：
   * 在*UCF-Crime* 和*XD-Violence* 上*VAD* 性能提升4-6% *AUC*
   * 在*UBnormal* 上提升3% *AUC*，在*MSAD*上也表现良好
   * *VAL* 和*VAU* 任务上相比零样本基线有显著提升
5. ​**无需训练**​：完全基于冻结的*VLM* 和*LLM*，通过测试时推理实现性能提升，无需任何梯度更新或额外数据。

# 3.实现流程

* **时序异常检测**：1️⃣初始评分器. 对于视频 $$V = [f_1, ..., f_T]$$，对每个帧$$f_i$$ 及其周围的*clip* $$c_i$$按照公式1操作,得到初始帧级异常分数 $$S_V = [s_1, ..., s_T]$$.2️⃣分数引导的异常提取. (1). ​**寻找最可疑窗口**​：滑动窗口寻找平均分数最高的长度为 $$\ell$$ 的窗口,如下公式2. (2)  ​**计算代理视频级分数**,如下公式3. (3) ​**提取异常标签列表**​,使用VLM分析最可疑片段,如下公式4.3️⃣基于分数的推理门控.  当$$\tilde{s}_V \in [0.5 \pm m]$$ 时（接近决策边界，表示不确定），触发二次推理.
$$
s_i = \theta_{LLM}(p_{VAD} \oplus \theta_{VLM}(c_i, p_{caption}))	\quad(1)
$$

$$
W_{max} = \arg\max_{W \subseteq {1,...,T}, |W|=\ell} \mu(W)	\quad(2)
$$

$$
\tilde{s}​*V = \mu(W*​{max})	\quad(3)
$$

$$
V_{sus} = [f_j], j \in W_{max}\\t_V = \theta_{VLM}(V_{sus}, p_{extract})	\quad(4)
$$

* **空间定位与文本理解**:  1️⃣空间定位.  使用检测能力的VLM $$\theta_{LOC}$$ 和细化的提示词对异常帧进行边界框预测。
  ![架构图](https://pic1.imgdb.cn/item/690f22343203f7be00e420de.png)

# 4.实现细节
​**VAD任务**​：

* clip采样步长：16帧
* 可疑窗口长度：$$\ell = \max(300, T/10)$$
* 门控宽度：$$m = 0.05$$（固定）或 $$\tilde{m}_V = \text{Var}(S_V)$$（自适应）
* 从$$W_{max}$$ 均匀子采样最多180帧提取 $$t_V$$
* 高斯平滑：$$\sigma = 10$$，truncate = 4.0

​**VAL任务**​：

* 置信度阈值：$$\tau = 0.5$$
* 评估指标：Temporal IoU (TIoU)

​**VAU任务**​：

* 每视频采样16帧
* 评估指标：BLEU, CIDEr, METEOR, ROUGE, GPT-R/D/C


## 4.4 提示词设计

**帧描述提示** ($$p_{caption}$$)：

```
You are an AI assistant analyzing this video segment.
Summarize the main events or actions in a concise way.
```

**VAD评分提示** ($$p_{VAD}$$)：

```
How would you rate the scene described on a scale from 0 to 1, 
with 0 representing a standard scene and 1 denoting a scene 
with {dataset_prior} activities?
Please respond with only one number in [0, 0.1, ..., 1.0].
```

其中 `dataset_prior` 针对不同数据集设置：

* UCF-Crime: "suspicious or potentially criminal"
* XD-Violence: "suspicious or violent"
* UBnormal: "suspicious activities"

**标签提取提示** ($$p_{extract}$$)：

```
Analyze the video interval to identify any possible suspicious behaviors.
Return your answer strictly as a Python-style list of phrases.
```

**定位提示** ($$p^*_{LOC}$$)：

```
The video could contain the following anomaly type: '{t_V}'.
Localize the suspicious region in this image.
Return in JSON format: [{"bbox_2d": [x1, y1, x2, y2], "confidence": c}].
```

# 5.模型性能

## 5.1 视频异常检测(VAD)性能

| 方法                    | 训练       | UCF-Crime       | XD-Violence           | UBnormal       | MSAD           |
| ------------------------- | ------------ | ----------------- | ----------------------- | ---------------- | ---------------- |
|                         |            | AUC(%)          | AUC(%) / AP(%)        | AUC(%)         | AUC(%) / AP(%) |
| RTFM                    | ✗         | 83.31           | -/77.81               | 86.7           | 66.3           |
| CLIP-TSA                | ✗         | 87.58           | -/82.19               | -              | -              |
| Holmes-VAU              | ✗         | 88.96           | -/87.68               | -              | -              |
| VERA                    | ✓(免训练) | 86.55           | 88.26/70.54           | -              | -              |
| LAVAD                   | ✓(零样本) | 80.28           | 85.36/62.01           | -              | -              |
| **Ours(固定m)**   | ✓(零样本) | **84.28** | **91.34/68.07** | **85.9** | **76.4** |
| **Ours(自适应m)** | ✓(零样本) | **84.08** | **91.23/68.03** | **86.0** | **75.9** |

​**关键发现**​：

* 相比最佳零样本基线(LAVAD)，UCF-Crime提升4%，XD-Violence提升6%
* 在UBnormal合成数据集上提升3%
* 接近甚至超越部分需要监督训练的方法

## 5.2 消融实验

### IntraTR组件有效性

| LLM评分 | 先验推理 | 分数门控 | UCF-Crime AUC(%)        |
| --------- | ---------- | ---------- | ------------------------- |
| ✗      | ✗       | ✗       | 77.67 (基线)            |
| ✓      | ✓       | ✗       | 77.40 (-0.27)           |
| ✓      | ✗       | ✗       | 80.38 (+2.71)           |
| ✓      | ✓       | ✓       | **84.28 (+6.61)** |

​**结论**​：无选择性门控的推理会引入噪声，选择性推理至关重要。

### 异常先验的影响

| 异常先验                            | UCF-Crime AUC(%) |
| ------------------------------------- | ------------------ |
| 空 \$$p\_{VAD}\$$                     | 81.86            |
| \$$\\oplus t\_{oracle}\$$（真实类别） | 83.91            |
| \$$\\oplus t\_V\$$（提取的标签）      | **84.28**  |

​**结论**​：自动提取的 $$t\_V$$ 甚至优于真实类别名，因为提供了更清晰的上下文。

### 门控宽度 $$m$$ 的敏感性

| m值               | UCF-Crime       | XD-Violence     | UBnormal        |
| ------------------- | ----------------- | ----------------- | ----------------- |
| 0.05              | **84.28** | **91.34** | 68.97           |
| 0.10              | 83.10           | 91.40           | 69.52           |
| 0.20              | 83.57           | 91.60           | **70.33** |
| 0.40              | 79.21           | 90.81           | 70.59           |
| \$$\\tilde{m}\_V\$$ | 84.08           | 91.23           | 69.02           |

​**结论**​：$$m \leq 0.2$$ 时性能稳定；合成数据集(UBnormal)受益于更大的 \$$m\$$。

## 5.3 空间定位(VAL)性能

| 方法                 | TIoU(%)         |
| ---------------------- | ----------------- |
| VadCLIP              | 22.05           |
| STPrompt             | 23.90           |
| Qwen2.5-VL-7B (基线) | 24.09           |
| + $$t_V$$ (Ours)    | **25.17** |
| + $$t_{oracle}$$    | 25.21           |

​**结论**​：注入异常标签带来~1%的绝对提升，$$t_V$$ 与真实标签性能相当。

## 5.4 视频异常理解(VAU)性能

### UCF-Crime数据集

| 方法               | BLEU            | CIDEr           | METEOR          | ROUGE           | GPT-R           | GPT-D           | GPT-C           |
| -------------------- | ----------------- | ----------------- | ----------------- | ----------------- | ----------------- | ----------------- | ----------------- |
| InternVideo2.5-8B  | 0.159           | 0.011           | 0.088           | 0.103           | 0.240           | 0.266           | 0.205           |
| VideoChat-Flash-2B | 0.165           | 0.008           | 0.108           | 0.168           | 0.488           | 0.283           | 0.404           |
| + InterTC (Ours)   | 0.297           | 0.022           | 0.157           | 0.188           | 0.509           | 0.427           | 0.438           |
| VideoLLaMA3-7B     | 0.215           | 0.014           | 0.117           | 0.156           | 0.463           | 0.289           | 0.384           |
| + InterTC (Ours)   | **0.345** | **0.023** | **0.175** | **0.188** | **0.512** | **0.428** | **0.444** |
| Hawk (微调)        | 0.379           | 0.008           | 0.217           | 0.187           | 0.255           | 0.580           | 0.214           |
| HolmesVAU (微调)   | 0.435           | 0.021           | 0.194           | 0.257           | 0.448           | 0.356           | 0.391           |

### XD-Violence数据集

| 方法               | BLEU            | CIDEr           | METEOR          | ROUGE           | GPT-R           | GPT-D           | GPT-C           |
| -------------------- | ----------------- | ----------------- | ----------------- | ----------------- | ----------------- | ----------------- | ----------------- |
| VideoChat-Flash-2B | 0.277           | 0.026           | 0.144           | 0.186           | 0.690           | 0.576           | 0.627           |
| + InterTC (Ours)   | 0.324           | 0.033           | 0.158           | 0.187           | 0.715           | 0.649           | 0.655           |
| VideoLLaMA3-7B     | 0.290           | 0.022           | 0.141           | 0.169           | 0.568           | 0.487           | 0.499           |
| + InterTC (Ours)   | **0.399** | **0.029** | **0.198** | **0.200** | **0.721** | **0.707** | **0.668** |
| Hawk (微调)        | 0.375           | 0.016           | 0.176           | 0.188           | 0.408           | 0.586           | 0.365           |
| HolmesVAU (微调)   | 0.376           | 0.011           | 0.182           | 0.253           | 0.715           | 0.581           | 0.673           |

​**关键发现**​：

* InterTC显著提升所有基线VLM的VAU性能
* 在多个指标上缩小与微调方法的差距，部分指标甚至超越
* 标签提示 $$t_V$$ 贡献最大，定位覆盖带来额外增益

### InterTC组件消融

| 数据集 | 标签$$t_V$$ | 边界框 | BLEU             | CIDEr            | METEOR           | ROUGE            |
| -------- | -------------- | -------- | ------------------ | ------------------ | ------------------ | ------------------ |
| UCF    | ✗           | ✗     | 0.2147           | 0.0143           | 0.1167           | 0.1564           |
| UCF    | ✓           | ✗     | 0.3328           | 0.0183           | 0.1684           | 0.1920           |
| UCF    | ✓           | ✓     | **0.3453** | **0.0232** | **0.1750** | 0.1878           |
| XD     | ✗           | ✗     | 0.2897           | 0.0219           | 0.1410           | 0.1690           |
| XD     | ✓           | ✗     | 0.3857           | 0.0270           | 0.1931           | 0.1993           |
| XD     | ✓           | ✓     | **0.3993** | **0.0288** | **0.1980** | **0.1997** |

​**结论**​：标签先验是主要贡献者，定位覆盖提供增量改进。

## 5.6 不同VLM/LLM组件的鲁棒性

| $$\theta_{VLM}$$ | $$\theta_{LLM}$$ | UCF-Crime AUC(%) |
| -------------------- | -------------------- | ------------------ |
| VideoLLaMA3-7B     | Llama-3.1-8B       | **84.28**  |
| VideoLLaMA3-2B     | Llama-3.1-8B       | 83.35            |
| Qwen2.5-VL-7B      | Llama-3.1-8B       | 83.23            |
| VideoLLaMA3-7B     | Llama-2-13B        | 80.70            |
| VideoLLaMA3-7B     | Llama-3.2-3B       | 81.09            |

​**结论**​：框架对不同VLM/LLM组合都保持80%+的AUC，证明了即插即用的特性。

## 5.7 效率分析

| 方法  | VLM描述 | 清理    | LLM总结 | LLM评分 | 细化    | 总计(秒/帧)       |
| ------- | --------- | --------- | --------- | --------- | --------- | ------------------- |
| LAVAD | 0.06736 | 0.01490 | 0.01684 | 0.01109 | 0.00673 | **0.11691** |
| Ours  | 0.02587 | -       | -       | 0.00314 | 0.00026 | **0.02927** |

​**结论**​：本方法比LAVAD快约4倍，因为选择性推理和更简洁的流程设计。

# 6.改进/挑战/问题/想法

## 6.1 主要优势

1. ​**真正的零样本**​：无需任何训练数据或梯度更新，完全依赖测试时推理
2. ​**任务统一**​：首次在单一框架下整合VAD、VAL、VAU三大任务
3. ​**可解释性强**​：不仅检测异常，还提供空间定位和文本解释
4. ​**高效推理**​：通过选择性门控避免不必要的推理，比基线快4倍
5. ​**模块化设计**​：即插即用，可以使用不同的VLM/LLM组合

## 6.2 局限性

1. ​**依赖预训练模型**​：性能受限于底层VLM/LLM的表征能力和先验知识，可能继承预训练数据的语义偏差
2. ​**细微异常检测能力有限**​：由于依赖冻结模型，对高度细微或领域特定的异常敏感性可能不如显式微调的模型
3. ​**短时事件捕捉不足**​：对于极短的异常间隔（如几帧），由于均匀采样策略，$$c_i$$ 可能缺乏必要的粒度
4. ​**输出冗余**​：有时生成过于详细的描述，符合LLM推理中发现的冗余输出趋势

## 6.3 伦理考量与社会影响

​**积极影响**​：

* 提升公共安全监控系统的异常检测和可解释性
* 减少对大规模标注数据的依赖

​**潜在风险**​：

* 改进的定位和描述能力可能被滥用于侵入性监控或画像
* 需要适当的治理、透明度和问责制
* 任何实际应用都应遵守隐私法律和伦理准则

## 6.4 未来改进方向

 **想法1：动态采样策略**

当前对 $$c_i$$ 的均匀采样可能错过极短事件。可以考虑：

* 基于初始分数密度的自适应采样
* 引入时间序列分割模型识别异常事件区间

 **想法2：多模态特征融合**

参考CoMM框架的思想，可以探索：

* 不仅对齐冗余信息，还建模独特性和协同性
* 使用Transformer融合不同模态特征到统一表示
* 从信息论角度（PID理论）分解多模态信息

**想法3：改进门控机制**

* 探索更复杂的不确定性估计方法
* 考虑多层次的推理深度控制
* 结合主动学习策略选择需要人工审核的样本

 **想法4：领域自适应提示**

虽然是零样本方法，但可以：

* 使用少量未标注视频自动提取领域特定的 `dataset_prior`
* 构建异常类型的本体库，增强提示词的语义丰富性
  
 **想法5：与CoMM结合的可能性**

将CoMM的多模态对比学习思想应用到视频异常分析：

* 学习视频-文本-音频的统一多模态表示
* 建模视觉、文本、音频特征的冗余、独特性和协同性
* 可能提升对复杂异常的识别能力


