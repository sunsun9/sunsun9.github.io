---
layout: post
title: 'Benchmarking the Robustness of Temporal Action Detection Models
Against Temporal Corruptions CVPR2024'
subtitle: '对时序动作检测模型进行鲁棒性基准测试，以防时序破坏'
date: 2024-11-29
author: Sun
cover: 'https://pic.imgdb.cn/item/67496910d0e0a243d4dad6d8.png'
tags: 论文阅读
---

> [Benchmarking the Robustness of Temporal Action Detection Models Against Temporal Corruptions](https://openaccess.thecvf.com/CVPR2024)
> 1深圳北理莫斯科大学人工智能研究院，2粤港澳情感智能与普适计算联合实验室，3深圳大学，4华南理工大学

# 1.文章针对痛点

时序动作检测（*TAD*）任务是为了检测一段未剪裁视频中，出现的动作时间和动作类别。文章在实践中发现，**视频中的时序信息会偶尔被破坏**，例如丢失或者模糊。而**这种破坏往往会导致现有模型方法的性能下降**，哪怕只有一帧受到损坏。

通过对几个先进方法的鲁棒性测试，原文发现：

* 现有的方法很容易受到时序破坏的影响，并且端到端的方法比那些具有预训练的特征提取器的方法更容易受到影响。
* 破坏主要来自定位错误而不是分类错误。
* 当破坏发生在一个动作实例的中间时，*TAD* 方法往往会具有最大的性能下降。

# 2.主要贡献

文章针对上面提到的痛点，提出了要增强模型的鲁棒性。具体来说，文章提出了两个小的创新方法。**首先**，文章提出了*FrameDrop*，一种增强策略；该策略从**视频的相邻动作或者背景中随机选择帧**，然后**引入损坏**从而破坏时间连续性。文章提出了**第二个**创新是*Temporal-Robust Consistency ( TRC )* 损失；这个损失是为了**在破坏视频和干净视频上对齐模型预测**；为了**增强对齐的效率**，文章还提出了一种**以动作为中心的采样策略**，这个策略是选择时间上与动作实例高相关的预测进行对齐。

原文将本文贡献总结为以下几点：

* 原文是第一个提出对时序动作检测模型进行全面稳健分析的。
* 原文创建了两个基准数据集，每一个包含了5中损坏类型和3种损坏程度。展示了现有方法在这个基准下有显著性能下降。
* 原文提出了一种简单而高效的训练方法来提高时间鲁棒性。

# 3.实现流程

由于这篇文章提出了的是对模型鲁棒性的基准测试，因此并未涉及较多的模型实现流程。整体来说，就是创建基准数据集，之后在各个先进方法模型上评测相应的模型鲁棒性。

# 4.实现细节

* **基准数据集创建**：原文引入了5种类型的破坏，分别是*black frame, motion blur（运动模糊）, overexposure, occlusion, packet loss* (视频在传输过程出现的包丢失)；此外，还引入了三种破坏程度，分别是破坏1%， 5%， 10%。需要注意的是，引入的破坏全部位于动作实例的中间部位。
* **鲁棒性评价指标**：显然鲁棒性评价取决于模型在应用域干净视频和破坏视频上性能的下降情况，但是需要注意的是，模型在干净视频上的性能也会影响性能下降情况。考虑到这一点，原文采取的是相对鲁棒性指标，即计算性能下降相对干净视频性能的比列，再用1减去该比例，得到最终的模型相对鲁棒性。另外这些计算都是基于*mAP* 指标的。
* **对*TAD* 模型的鲁棒性测试**：（1）首先是通过实验证明了，现有的方法对时序破坏的敏感性，面对破坏视频，会出现明显的性能下降。（2）通过实验证明，这种敏感性主要是由定位错误导致的，而不是分类错误。（3）通过实验证明，在动作实例中间引入破坏会导致最大的性能下降。

# 5.模型性能

这个因为不涉及到提出新的模型，所以没有什么模型性能。

# 6.改进/挑战/问题

* 对于这种损坏问题能不能使用一些生成模型修补损坏，然后再判断动作类别和时间边界。
* 问题：（1）针对引入损坏视频帧，文章中提到模拟真实世界数据。但是文章中的引入方式是按照一定的比例（原文选取的1%、5%和10%）在动作实例的中间部分引入破坏，原文提到这样做的原因是在中间部分引入，会造成性能更大的下降。但是**引入为什么不是随机的**，而是一定要在中间部位，这样做会不会弱化模型对其他部位破坏的鲁棒性能力；其次，原文提到的破坏引入是连续帧，这其实和上一个问题差不多，**为什么帧不是分散的，而是全部集中的**。所以这是不是真的模拟现实世界还值得考虑。
* 问题：（2）针对提高模型的鲁棒性，文章提出了两种方式，一种是在训练过程中对输入数据进行随机drop帧操作，这种方式是可理解的。但是文章还提出了第二种方式是时间鲁棒性一致性损失，这个应该也是在训练过程中，但是这个提到的是**将破坏视频和经过第一种方式处理的干净视频作为模型输入**，这种方法真的合理吗，因为在原文的片段中有提到在作鲁棒性测试的时候，训练数据集中不应该包含破坏视频数据。都直接针对鲁棒性测试要使用的破坏数据集训练了，鲁棒性提高不是必然的吗？？

