---
layout: post
title: 'FinePOSE: Fine-Grained Prompt-Driven 3D Human Pose Estimation via
Diffusion Models CVPR2024'
subtitle: 'FinePOSE：通过扩散模型地细粒度提示驱动地3D人体姿态估计'
date: 2024-11-14
author: Sun
cover: 'https://pic.imgdb.cn/item/67355485d29ded1a8c1821bb.png'
tags: 论文阅读
---

> [FinePOSE: Fine-Grained Prompt-Driven 3D Human Pose Estimation via Diffusion Models](https://openaccess.thecvf.com/CVPR2024)
> 一作院校是北京科技大学智能科学与技术学院，二作院校是北京大学

> 这篇文章提到了一个扩散模型，扩散模型其实也是一种生成式模型，包含增加噪声和去除噪声两个过程。输入数据通过逐步添加噪声，将数据变成纯噪声数据；而模型需要学习的就是去除噪声、恢复到原图像的过程。[具体可以扩散模型的内容可以参考这篇文章。](https://blog.csdn.net/DFCED/article/details/132394895)
> 
> 另一方面这篇文章其实是关于3D重建的，只不过是针对人体方面的。虽然与自己方向不太一样，但是关于扩散模型这个内容感觉是一个可以学习的方向。
> 
> 另外，个人觉得这个文章讲述的不是很清楚，虽然模块划分很清楚，但是原文讲述的工作部分感觉与提供的模型架构图并不是很符合。

# 摘要

*3D* 人体姿态估计(*human pose estimation, HPE*)任务使用*2D* 图像或者视频来预测人体在3D空间中的关节坐标。本文认为虽然一些基于深度学习的方法在这方面取得了一些进展，但是大部分方法忽略了结合可访问文本和人体自然可行知识的能力，从而错过了引导*3D HPE*任务的版规隐式监督。另一方面，本文认为先前的工作经常从整个人体的角度学习这项任务，忽略了隐藏在不同身体部分的细粒度引导。

为了解决这些问题，本文提出了*Fine-Grained Prompt-Driven Denoiser based on a diffusion model for 3D HPE, named FinePOSE*（*3D HPE*，基于扩散模型的细粒度提示驱动的降噪器）。*FinePose* 包含三个部分：**（1）*Fine-grained Part-aware Prompt learning (FPP) block*（细粒度部分感知提示学习模块）**。该模块通过用可学习提示来结合可访问文本和人体部分自然可行知识，构建了细粒度部分感知提示，从而模拟隐性指导。**（2）*Fine-grained Prompt-pose Communication (FPC) block*（细粒度提示姿态通信模块）**。该模块在可学习部分感知提示和姿态之间建立了细粒度通信，来提高去噪能力。**（3） *Prompt-driven Timestamp Stylization (PTS) block* （提示驱动的时间戳风格化模块）**。该模块通过集成可学习提示嵌入和与噪声级别相关的时间信息，从而能够在每个去噪步骤中能够自适应调整。

# 引言

*3D HPE* 通常呗分为两个阶段：（1）检测图像或视频中的*2D* 关键点；（2）将*2D* 关键点映射到3D人体姿态中。而本文所关注的就是第二个阶段。

现存的*3D HPE* 方法有三个挑战：（1）**不确定性**。文章认为现有的将*2D* 骨骼点映射到*3D* 骨骼点（一对多）的方法本质上存在深度模糊性。（2）**复杂性**。灵活的身体结构、复杂的关节间关系和较高的肢体自由度，容易导致自我遮挡或者罕见复杂的姿态。（3）**推广性**。文章认为现有的公开的可用数据集在动作类别上有限，在这些数据上训练的模型已经被证明会产生过拟合，并且很难推广到更多样的动作类别数据中。

为了解决这些问题，本文提出了通过增强输入信息来提高3D HPE模型的性能。作者发现现有的方法忽略了可利用的文本和人体自然可行的知识，并且这些信息是能够给模型提供指导的。所以本文利用了（1）人体姿态的动作类别，（2）运动信息”速度“，（3）不同人体部位在人体运动中的移动方式；来构建细粒度部分感知提示。具体来说，本文将细粒度部分感知提示学习机制集成到本文的框架中，通过视觉语言模型驱动3D人体姿态估计。该机制可以自适应地学习不同人体部位的修饰符，从多个粒度（包括动作类别、速度、整个人和细粒度人体部位）精确描述其运动。（这种新机制与扩散模型相结合）

总的来说，本文提出了一种基于扩散模型的细粒度提示驱动去噪器 (FinePOSE)，该模型由细粒度部分感知提示学习 (FPP) 块、细粒度提示姿势通信 (FPC) 块和提示驱动的时间戳风格化 (PTS) 块组成。具体来说，***FPP* 块**对人体姿势的三种信息进行编码，包括动作类别、人体的粗粒度和细粒度部分（如“人、头、身体、手臂、腿”）和运动信息“速度”，并将它们与姿势特征相结合以服务于后续过程。然后，***FPC* 块**将细粒度部分感知提示嵌入到噪声 *3D* 姿势中，从而在可学习的部分感知提示和姿势之间建立细粒度通信，增强去噪能力。为了处理具有不同噪声水平的 3D 姿势，***PTS* 模块**将时间戳与细粒度部分感知提示嵌入引入到去噪过程中，以增强其适应性并细化每个噪声水平的预测。

# 相关工作

本文从扩散模型、*3D* 人体姿态估计、提示学习三个方面阐述的相关工作。**扩散模型**在文章开头已经提到了，这里就不再说明。***3D* 人体姿态估计**其实前面两个部分也已经提到了相关概念和定义，原文的这个部分主要讲述了一些相关工作（具体可以阅读原文）。**提示学习**这里指的是文本提示，随着大语言模型的发展，文本提示在计算机视觉上的应用也越来越广泛了，重要代表模型就是*CLIP*，之后的很多视觉语言模型都是在*CLIP* 的基础上改进或者直接运用*CLIP* 的编码器。本文也是直接使用了*CLIP* 的文本编码器，编码了多粒度文本特征。

# 原文工作

前面已经提到，这篇文章解决的问题就是利用2D关节点，得到3D人体姿态估计。FinePose具有三个模块，分别是*Finegrained Part-aware Prompt learning (FPP), Fine-grained Prompt-pose Communication (FPC), and Prompt-driven Timestamp Stylization (PTS)*。

整个模型是基于扩散模型的3D人体姿态估计器，所以模型的主要任务就是从高斯噪声分布中还原得到不含噪声干净的3D人体姿态。根据前面的介绍，我们知道扩散模型包含两个过程；（1）加噪声过程，对于加噪声过程，原文使用了一个时间戳嵌入神经网络，可以自适应调整加入高斯噪声的数量。（2）去噪过程。具体的过程后面会详细描述，但是整体来说，去噪是一个迭代过程。模型整体架构图![](https://pic.imgdb.cn/item/6733150cd29ded1a8c5ae1ee.png)

***Finegrained Part-aware Prompt learning (FPP)***：这个模块包含三部分输入，分别是动作类别、粗-细粒度人体部位以及运动信息*speed*。从上面架构图中可以清楚了解到该模块的输入部分，这些输入会经过*CLIP* 编码器得到一个可学习的提示嵌入。**值得注意的是**，原文认为经过文本编码器后会发现有效*tokens* 的数量是3-4个，因此，只保留了每个文本提示的前4个*token*。另外在得到所有需要的*tokens* 后，原文为每一个*token* 连接的一个可学习向量（初始化是一个高斯分布）。这个设计原文给出的解释是，修饰符可以帮助准确描述身体部位的运动，个人猜测这个可学习向量就是所谓的修饰符，但是这个修饰符对应到输入的文本中，不知道是不是动作描述的修饰词。

***Fine-grained Prompt-pose Communication (FPC)***：在获取细粒度部分感知嵌入*P* 后，原文想要在可学习部分感知提示和姿态之间建立通信，从而提高降噪能力。**首先**，FPC模块会将*Y*<sub>*t*</sub> 与引导信息进行连接或者加法操作，按照公式*Z*<sub>*t*</sub> = *Concat(Y*<sub>*t*</sub> *, X)* + *P[L]+F(t)* 操作。这个*F(t)* 函数就是前面提到的关于时间戳的嵌入神经网络，得到的*Z*<sub>*t*</sub> 就是图中*FPC* 部分灰色矩形的输出，**经过多头自注意力机制后**，得到每帧关节之间关系*Z*<sub>*t*</sub><sup>*s*</sup>；之后相当于一个**残差连接**。原文中提到为了完全将提示嵌入注射到*Z*<sub>*t*</sub><sup>*s*</sup>，引入了**多头交叉注意力模型**，其过程可以公式化为下图表示。至于图中后面的也是彩色模块的部分，个人猜测要么就是使用了两次，要么就是表示去噪过程所谓的迭代。
多头注意力模型公式表示![多头注意力模型公式](https://pic.imgdb.cn/item/67332c1ed29ded1a8c71a2a3.png)

***Prompt-driven Timestamp Stylization (PTS)***：为去噪过程提供时间戳嵌入对于处理具有不同噪声水平的 *3D* 姿势至关重要。因此，受 其他文章的启发，原文引入了 *PTS* 块，该块通过位置嵌入明确嵌入时间戳 *t*，并将其与 *FPP* 块获得的可学习提示嵌入 *P* 相加，即 *v=P[L]+F(t)*。给定 *FPC* 块的中间输出，可公式表示为下图。但是这里我觉得很奇怪的是，按照这里的描述，*PTS* 块的输入应该有*v*（即*P* 与时间戳神经网络的加法操作输出结果），但是在原文展示的图中，这部分输入时*PTS* 块上一个模块的输入。这个地方不是很理解。![PTS块](https://pic.imgdb.cn/item/67332da1d29ded1a8c735414.png)

后面，原文提到了推理过程（降噪）是怎么工作的，感觉就是重点把握**迭代**吧，就是这一次的输出就是下一次的输入。最后也提到多人人体姿态估计，这个就是得到每个人的人体姿态估计，然后进行堆叠。

# 实验

文章在三个数据集，分别是*Human3.6M*、*MPI-INF-3DHP*、*EgoHumans* 进行了实验，在*Human3.6M* 进行了消融实验研究，*EgoHumans* 这个数据集用于测试多人场景下的效果。

* 该部分首先在前两个数据集下与目前的SOTA方法进行了比较，实验结果肯定是提升了。
* 在*Human3.6M* 数据集上进行了消融实验研究。研究的就是本文提出来的三个模块效果怎么样，以及什么样的提示效果会更好（就是*FPP* 模块不同设计的效果）。

