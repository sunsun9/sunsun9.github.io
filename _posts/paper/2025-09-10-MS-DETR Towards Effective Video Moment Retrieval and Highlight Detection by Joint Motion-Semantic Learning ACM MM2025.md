---
layout: post
title: 'MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning ACM MM2025😊'
subtitle: 'MS-DETR: 通过联合动作-语义学习 面向有效的视频时刻检索和高光检测'
date: 2025-09-10
author: Sun
cover: 'https://pic1.imgdb.cn/item/68bfb55058cb8da5c88e4885.png'
tags: 论文阅读
---

> [MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning](https://arxiv.org/abs/2507.12062)

> 💐💐[项目主页](https://github.com/snailma0229/MS-DETR)
> 
> 📌作者单位
> 
> 1. 复旦大学
> 2. 腾讯优图实验室

# 1.文章针对痛点

这篇文章关注的是时刻检索和高光检测的联合学习，前者是检测视频中与文本相关的视频片段，并给出准确的时间边界；后者是预测视频片段与文本的相关性。

文章认为目前联合学习的方法虽然使用基于DETR的方法取得了重要的进展，但是在视频内容的时间动作和空间语义的复杂关系处理上还存在很大的未开发空间；并且，在两个任务的联合上并没有做到深入的互惠；另外，视频内容的丰富性是远超于文本所描述的内容，即两个任务的数据集存在动作和语义维度上的固有稀疏难题。

# 2.主要贡献

针对这些问题，文章提出了一个新型的联合*MR/HD* 框架，提出了*MS-Detress*（*MS-DETR* ），该框架可以有效推进运动和语义联合学习策略。文章首先设计了一个**动作-语义分离编码器**，能够明确区分视频中的时间动作和空间语义维度，并且在两个维度上能够和文本查询进行更细粒度信息的整合。
然后，为了促进运动 - 语义维度的*MR* 和*HD* 任务之间更好的同步和协同作用，文章提出了相互的任务处理解码器（*MTCD* ）。利用*HD* 任务的显着性预测来动态生成具有运动和内容查询的时间位置查询。 *HD* 提供的查询作为一个先验知识来引导MR任务中定位相关性时刻。以互惠的方式，将*MR* 任务中准确的时间界和语义前景约束用于完善*HD* 任务中显着性预测的判别。
最后，为了解决固有的稀疏注释难题问题，文章从时间运动和空间语义维度都丰富了数据，旨在在运动级别的方面在数据级上实现视频和文本之间的丰富性一致性。为了处理用于充分利用的辅助数据中不可避免的噪声，引入了可靠的培训训练策略，以进行可靠的培训，并在匹配（*pos* ）和未匹配的（*neg* ）视频文本对之间进行明确的对比度度量学习。

原文总结贡献如下：

1. 我们提出了一个由*MSDE* 组成的统一*MR/HD* 框架*MS-DETR*，以了解基于文本查询的更多细微差别的动作-语义视频表示，并利用*MR/HD* 之间的相互协同益处在运动-语义中的*MR/HD*。
2. 我们介绍了语料库生成，以解决这两个维度的稀疏注释难题，并提出对比性的去噪学习，从而从生成的数据中学习可靠学习。
3. 我们的方法在四个基准测试上优于所有现有的*SOTA*。

# 3.实现流程

文章提出模型的架构图如下所示。

![模型架构图](https://pic1.imgdb.cn/item/68bfbf2f58cb8da5c88e968b.png)

# 4.实现细节

* **动作-语义分离编码器**：该部分是为了有效整合基于查询的动作和语义视觉表示。因此，文章引入了时间动作和空间语义跨模态*Transformers* 处理不同模态特征之间的交互。公式如下，其中*SSCT* 关注候选片段的上下文相关性的静态视觉细节，而*TMCT* 捕获连续片段之间的动态和过渡信息，从而有助于模型理解顺序和长度。
  
  $$
  \hat{F}_{v}=\phi\left(\left(\mathrm{TMCT}(Q_{v}^{m},K_{t},V_{t})\oplus\mathrm{SSCT}(Q_{v}^{t},K_{t},V_{t})\right)\right)
  $$
* **互任务合并解码器**：这个模块设计是针对当前的一些方法都是使用随机初始化的查询来定义位置或者全0查询来定义语义查询，针对这个问题，文章提出可以使用*MD* 任务获取的显著性预测来初始化*MR* 任务的查询；具体来说，文章从编码器的输出中选择*topK* 个显著性分数作为语义内容的查询$$Q_c$$，公式如下1所示，其中$$S(x_i)$$的计算如下公式2所示。同时，考虑到空间语义和时间位置之间的固定关系，文章使用前面的语义查询$$Q_c$$生成相关位置，如下公式3，并按照公式4计算得到时间位置编码。

$$
Q_{c}=\{x_{k}\in X^{\prime}|k\in\mathrm{top-K}(S(x_{k}))\}	\quad(1)
$$

$$
S(x_i)=\frac{\omega_s^Tx_s\cdot\omega_v^Tx_i}{\sqrt{d}}	\quad(2)
$$

$$
R_k=\mathrm{MLP}_{Span}\left(q_k\right),\quad q_k\in Q_c	\quad(3)
$$

$$
\Phi(R_k)=\left(\sin\left(\frac{2\pi R_k}{10000^{2i/\frac{d}{2}}}\right)\oplus\cos\left(\frac{2\pi R_k}{10000^{(2i+1)/\frac{d}{2}}}\right)\right)	\quad(4)
$$

* **在辅助数据集上的对比去噪训练**：这个模块设计主要是考虑到两个任务会受到数据集固有的动作-语义维度稀疏的难题，因此，文章在这部分新构建了一部分文本语料库，这一部分主要就是讲的怎么构建的语料库，以及语料库怎么去噪。从时间和空间角度分别构建了两个维度的语料库，时间上主要是明确动作时间顺序，空间上主要是替换动词；另外替换名词和动词为反义词构成负样本。![构建图](https://pic1.imgdb.cn/item/68c1163658cb8da5c8953d07.png)

# 5.模型性能

![模型性能1](https://pic1.imgdb.cn/item/68c116bf58cb8da5c89540cf.png)
![模型性能2](https://pic1.imgdb.cn/item/68c116dd58cb8da5c89541b6.png)

# 6.改进/挑战/问题/想法

* **想法**：

