---
layout: post
title: 'TriDet: Temporal Action Detection with Relative Boundary Modeling CVPR2023'
subtitle: 'TriDet: 具有相对边界建模的时序动作检测'
date: 2025-02-12
author: Sun
cover: 'https://pic1.imgdb.cn/item/67ac1ac7d0e0a243d4fe853b.png'
tags: 论文阅读
---

> [TriDet: 具有相对边界建模的时序动作检测](https://openaccess.thecvf.com/CVPR2023)
> 中国北京航空航天大学 VRLab   美团 京东

# 1.文章针对痛点

这篇文章关注的时序动作检测问题TAD。

这篇文章针对的问题是现有的方法由于视频中的动作边界不明确，从而导致模型往往会<mark>具有不准确边界预测问题</mark>。此外，文章提到了现有的几种方法的预测边界方法；其中有基于预测时间片段的全局特征定位边界的方法，这种方法容易忽视每个实例的详细信息；另外一种方法是基于单个时刻直接聚合边界，这种方法没有考虑到相邻时刻（也就是没有关注全局信息的问题）

# 2.主要贡献

因此，为了解决上述问题，促进定位学习；文章假设，视频中时间特征的相对响应密度能够减轻视频特征复杂度的影响、增加定位准确性。因此，文章提出了*TriDet* 架构。

包**含一个新的检测头*Trident-head*，专门用于动作边界定位**。具体来说，提出的新的检测头不是基于中心点特征直接预测边界偏移，而是通过估计的边界相对概率分布来建模动作边界。（原文展示了边界预测方法的对比）

此外**还提出了一个高效的可扩展粒度感知层*SGP*，来缓解出现在视频特征中的自注意力秩损失问题，同时聚合不同时间粒度的信息**。*SGP* 层包括两个主要分支，有助于增加每个实例特征的判别信息，并能够捕获不同尺度感受野的时间信息。

# 3.实现流程

还是先看一下整体的架构图![整体的架构图](https://pic1.imgdb.cn/item/67a70156d0e0a243d4fcf8f4.png)
这个也是很经典的模型结构，前面就是输入视频，使用*backbone* 提取视频特征，后面是文章新提出的一个模块，用于处理增强特征吧，后面就是分类头和边界预测头。

# 4.实现细节

* **backbone**：这个模块就不用多说了，一般都是使用预训练好的网络结构提取，e.g. I3D等等。
* **SGP特征金字塔**：这个模块设置是<mark>为了解决传统的*transformer* 使用自注意力带来的秩损失（导致得到的特征之间相似度较高）和计算复杂的问题。</mark>因此，提出了该模块，这是一个可扩展粒度感知层，可以高效捕捉动作信息并解决秩损失问题，与传统的*transformer* 结构的不同，如下所示。![对比](https://pic1.imgdb.cn/item/67a70439d0e0a243d4fcfd77.png)*SGP* 层包含两个分支，分别是实例分支和窗口分支（也就是处理的特征所对应的时间维度不同）。前者是为了增加动作时刻和非动作时刻之间的特征判别，后者是动态关注对应尺度的特征。
  
  该模块可以用下列公式表示，其中，$$\phi$$和$$\psi$$如下列公式所示。对比传统的结构来看，*SGP* 模块减少了计算量是显而易见的事，虽然具有两个分支结构，但是相对自注意力大量的成对计算，还是计算相对简单。
  
  在（1）这个公式中*w* 表示窗口大小，*k* 是可扩展因素，目的是为了捕获更大粒度的时间信息（个人感觉这个*k* 是对应前面金字塔中的参数）

$$
f_{S G P}=\phi(x) F C(x)+\psi(x)\left(\operatorname{Conv}_{w}(x)+\operatorname{Conv}_{k w}(x)\right)+x,	(1)
$$

$$
\phi(x)  =\operatorname{ReLU}(F C(\operatorname{AvgPool}(x))), 	(2)\\
\psi(x)  =\operatorname{Conv}_{w}(x),	(3)
$$

* **分类头**：分类头模块也不多介绍了，个人其实感觉在TAD任务中，分类并不是主要任务，所以大部分TAD研究工作也是在关注边界预测定位问题，并没有过多关注分类问题。
* **Trident-head 边界预测头**：在边界预测上，文章认为现有的方法要么关注一个视频片段的全局特征，从而忽略了详细特征（也就是更精细的局部特征）；要么只关注单帧特征，但是忽略了与其他帧之间的联系。因此，为了避免这些问题，文章提出了一个新的模块*Trident-head*；目的就是为了准确定位动作边界，<mark>考虑一定时间内的特征联系，并获得该时期内每个时刻的边界相对概率（也就是每个时刻预测为边界的概率）。</mark>整体流程图如下所示：![Trident-head](https://pic1.imgdb.cn/item/67a70c01d0e0a243d4fd02b0.png)
  
  *Trident-head* 模块包含三个部分，分别是开始头，结束头和中间偏移头，这三个头也分别对应开始位置、结束位置和动作的时间中心。这个模块在获得金字塔的输出后，会通过这三个分支将其处理为三个特征序列。再处理这三个序列获得最终的边界位置和中心位置。
  
  中心思想就是根据条件分布计算预测中心位置到边界的距离，如下公式所示，其中公式（1）是计算中心位置与开始边界之间的距离；类似地，公式（2）计算的中心位置与结束边界之间的距离。（公式中，b表示的是选择的箱）

$$
\begin{aligned}
 & \widetilde{P}_{st}=Softmax(F_{s}^{[(t-B):t]}+F_{c}^{t,0}), \\
 & d_{st}=\mathbb{E}_{b\sim\widetilde{P}_{st}}[b]\approx\sum_{b=0}^{B}(b\widetilde{P}_{stb}),
\end{aligned} （1）
$$

$$
\begin{aligned}
 & \widetilde{P}_{et}=Softmax(F_{e}^{[t:(t+B)]}+F_{c}^{t,1}), \\
 & d_{et}=\mathbb{E}_{b\sim\widetilde{P}_{et}}[b]\approx\sum_{b=0}^{B}(b\widetilde{P}_{etb})
\end{aligned}（2）
$$

# 5.模型性能

这篇文章的代码跑了一下，最后的性能和论文写的差不多，有细微浮动。其次，这篇文章是一阶段方法，相对于现在较流行的端到端方法来说，个人感觉改进难度相对较大，结合多模态难度也较大。目前大模型比较流行，如果不结合大模型的话，感觉做出来的动作很难接收。

# 6.改进/挑战/问题

* **问题**：对于这个特征金字塔部分还不是很理解，后面会去看一下其他教程，代码部分的话，因为是简单看了一下关键代码，好像没有看到关于金字塔这部分。
* **改进**：与前面说的一样，我觉得这种非端到端的结构，如果是将其他论文的模块结合到这上面来，相对来说难度较大，并且效果不一定好。这种非端到端的，我认为还是需要自己创新功能模块。

