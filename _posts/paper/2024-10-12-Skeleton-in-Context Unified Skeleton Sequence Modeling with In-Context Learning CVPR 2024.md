---
layout: post
title: 'Skeleton-in-Context Unified Skeleton Sequence Modeling with In-Context Learning CVPR 2024'
date: 2024-10-06
author: Sun
cover: 'https://pic.imgdb.cn/item/670a36bdd29ded1a8ca5d894.png'
tags: 论文阅读
---

> [基于上下文的骨架：统一骨架序列建模和上下文学习](https://openaccess.thecvf.com/CVPR2024)

 > 这篇文章主要提出了基于上下文的骨架序列统一建模，利用提示对让模型自主感知任务，并利用TUP让模型获取目标序列的先验知识。这种结合方式解决了之前在2D和3D上下文模型中常用训练框架，用于训练骨架序列出现的过拟合问题。本文构建的模型可以推广到不同的数据集和新任务中。
 > 端到端模型；一次训练；多任务处理

# 摘要

上下文学习是目前的一种新型学习技术，为cv和nlp的[多任务建模](#001)提供了一种新视角；目前主要应用于自然语言处理领域，尤其是大模型。这种方式能够在没有明确（任何额外特定任务）训练或模型微调的情况下，通过提供上下文示例来理解任务并进行推断。

上下文学习在骨架序列建模中还未被探索。由于[帧间的相似性和跨任务姿势的相似性](#002)，使得模型在微妙的上下文中感知任务是很难的；因此，直接使用其他领域现有的上下文模型应用于骨架序列上，效果是不好的。

为了解决这个问题，本文提出了*Skeleton-in-Context(SiC)*,一种基于上下文骨架序列建模的模型，可以在单个训练过程中同时处理多个基于骨架的任务，并且能够根据给定提示从上下文中完成每一个任务，对新任务也更具泛化性。同时为了促进对上下文的感知，本文额外提出了一种任务统一的提示，能够自适应地学习不同特性的任务。*SiC*在对任务处理上表现良好，在新任务上的泛化能力良好。

> 知识解释

1. <a id="001">**多任务建模**</a>：是一种机器学习方法，旨在同时学习多个相关任务，以提高模型的整体性能和泛化能力。它通过共享表示和知识，利用任务之间的相关性，来提高每个任务的学习效率。例如，图像分割、物体检测和图像分类可以作为多个任务在同一网络中共同训练。在多任务建模中，通常使用一个共享的基础模型，然后**在该模型的顶部添加任务特定的分支**。这种结构使得底层特征可以被多个任务共享。
2. <a id="002">**帧间的相似性和跨任务姿势的相似性**</a>：**帧间的相似性**指的是在视频或动作序列中，相邻帧之间的特征或姿势的相似性。**跨任务姿势的相似性**是指在不同任务之间（例如，行走、跳跃、踢球等），虽然任务不同，但某些姿势或动作可能存在相似性。帧间相似性强调的是同一任务中的连续帧之间的特征一致性。跨任务姿势相似性则关注于不同任务之间的姿势或动作模式的共同特性。

# 引言

对于这种多任务模型，大部分**先前工作**是基于一个共享backbone，重点部署特定任务的head，并且通过预训练或微调来学习。而这种具有特定任务架构的模型并不是以一种端到端的学习方式，对新任务的泛化能力较差。大部分**现有的基于骨架的以人为中心的任务**，也是依赖于特定任务设计或者并不是一种端到端的架构来完成多任务处理。目前的一些模型虽然具备良好的处理能力，但是缺乏灵活性，对新任务不具备好的泛化能力。

而上下文学习提供了一种建立通用模型的新趋势，通过学习[上下文示例（提示）](#003)来执行所需任务。上下文模型可以端到端的完成多种任务，并且不需要任何特定任务head或微调。具有良好的泛化能力，但是现有的基于上下文的模型大部分关注的是静态物体，因此无法捕捉到骨架序列的时空依赖。

所以，在本文中提出了一种框架*Skeleton-in-Context(SiC)*。*SiC*从上下文中感知任务，并且将任务的上下文提示作为额外输入，然后完成任务的query。*SiC*采用两种类型的提示来促进上下文感知：任务引导提示（TGP）和统一任务提示（TUP）。**1）**前者为模型提供任务模板，让模型有类比的能力（类比是模型在新任务具有泛化能力的关键）。**2）**后者有两种方式实现：静态的和动态的。静态TUP利用任务之间共享的先验知识，动态TUP自适应学习上下文感知。

因为目前没有基准来评估模型，本文基于四个任务建立了一种新的上下文基准，包括三个基于骨架的任务：动作预测、姿态估计和关节补充，以及一个新任务：未来姿态估计。

> 总结：本文就是基于上下文提出一种基于骨架解决多任务的端到端架构。

> 知识解释

1. <a id="003">**上下文示例（提示）**</a>：指提供输入输出对的上下文建模学习方式，原文示例图如下。![取自原文](https://pic.imgdb.cn/item/6704f789d29ded1a8c72ed47.png)

# 相关工作

本文从三方面阐述了相关工作。

> 基于骨架的动作分析

在**人体动作预测**上，早期的成功方法是使用RNN和CNNs；而现在，GCNs被广泛应用。后续出现的大部分方法集中于设计更好的图卷积网络。在**动作合成**任务上，为了补充人体动作的缺失部分，许多工作采用卷积模型或生成对抗网络。但是这些方法都关注设计特定任务的定制结构，应用范围受限。

为了解决这些问题，本文提出了统一多任务的输入输出格式，并利用单个模型通过上下文学习来同时处理多个任务。

> 上下文学习

上下文学习最初用于nlp任务中，它赋予模型解决多任务甚至是新任务的能力，通过将特定领域的输入-目标对纳入查询样本中。之后，上下文学习也被扩展到cv任务中。本文的工作主要是深入建模上下文动态骨架序列。

> 统一以骨架为中心的模型

先前的工作都是探索几个以人为中心任务的共训练，最近的工作证明建模统一人体动作序列的有效性。但是，这些工作仍然受限于复杂训练阶段或任务heads的困境，增加了额外的消费。本文将不同任务的输出格式整合成骨架序列格式，并且仅训练模型一次。

> 个人想法：目前基于骨架的行为识别大多数都是应用GCNs，因为骨架数据不受光照、背景等因素的影响，数据更稳定；但是骨架数据更偏向于一种图结构，而CNNs和RNNs无法有效处理这种无序的图结构数据。
> 
> 本文想要解决的问题是构建一个端到端的统一模型来处理多任务问题，而目前相关工作大部分是根据特定任务构建定制的结构，即并非是端到端的模式，这种架构也会引入一些额外的消费。

# 本文提出的模型SiC

整体架构如下：![figure2](https://pic.imgdb.cn/item/670a29bed29ded1a8c93d0eb.png)
**输入**：模型的输入有两部分构成，首先是一个提示输入-目标对，用于让模型在提示对中感知上下文任务。另外一部分输入是模型真实想要预测或处理的查询输入。
**过程**：

1. 本文根据要处理的多任务，包括关节点补充、动作预测、姿态估计和未来姿态估计这四个任务，构建了一个骨架库，包含了四个任务所有的提示对。
2. 随机从骨架库中选择一个提示对作为模型的提示对输入，拼接两个序列。并输入查询输入。将两个输入分别映射到C为特征空间中。
3. 从骨架库中获取所有的目标数据(target)，取平均，得到Static-TUP and Dynamic-TUP，代表了目标骨架序列的先验知识。之后与映射后的查询输入拼接。
4. 从图中可以看到，拼接之后的数据格式是(2F, J, C)。之后将空间注意块和时间注意块以交替组合的方式连接在一起，形成一个专用于捕捉运动动态特征的双流transformer。论文中使用公式如下：![公式](https://pic.imgdb.cn/item/670a31c9d29ded1a8c9f4527.png)
5. 将前面得到的输入-目标对拼接得到的数据和查询输入和TUP拼接得到数据作为transformer的输入，经过n1次迭代。
6. 将两个transformer得到的输出经过聚合函数进行积分，再输入transformer中，经过n2次迭代。得到输入结果，并把输入结果的后半部分作为模型最后的输出。（其中n1+n2=N)

**结果**：经过实验，本文得出N=5，多头注意力数目为8，隐藏特征维度为256，序列长度F=16。所有的任务都是一次端到端的训练完成，不需要任何特定任务设计。

