---
layout: post
title: 'Number it: Temporal Grounding Videos like Flipping Manga CVPR 2025'
subtitle: '编号：像翻阅漫画那样的时间定位视频'
date: 2025-05-24
author: Sun
cover: 'https://pic1.imgdb.cn/item/6831563658cb8da5c80b2cb9.png'
tags: 论文阅读
---

> [Number it: Temporal Grounding Videos like Flipping Manga](https://arxiv.org/abs/2411.10332)

> 💐💐[提供代码](https://github.com/yongliang-wu/NumPro)
> 
> 📌作者单位
> 
> 1. 东南大学
> 2. Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications (新一代人工智能技术及其交叉应用教育部重点实验室，东南大学)
> 3. Max Planck Institute for Informatics
> 4. 腾讯微信视觉团队
> 5. 加州大学伯克利分校

# 1.文章针对痛点

这篇文章关注的问题是视觉大语言模型，在时间定位上不准确的问题。

文章认为要将视觉信息转换成准确的时间定位，比如具体某一秒或者某一帧是十分困难的。<mark>认为视觉大语言模型增强了模型识别视频中事件的能力，但是这种能力本质上不能用语言描述事件开始和结束时刻</mark>。产生这种局限性的原因是，这些模型主要被训练来使视觉内容与语言描述（发生了什么）相一致，而缺乏直接解释时间界限（何时发生）的机制。


# 2.主要贡献

所以针对上面的这个问题，文章引入了*Number-Prompt (NumPro)*，赋予每一个视频帧独一无二的编号。

具体而言，*NumPro* 为每个帧添加了唯一的数字标识符，表示其在时间序列中的位置。给定一个以事件为目标的语言查询，*Vid-LLM* 会检索视频帧的相关视觉特征，并将其与叠加的帧编号联系起来。然后，这些数字标识符被直接转化为文本输出。在实践中，文章将帧编号置于右下角，并使用规定的字体大小和独特的颜色。这种设计确保了数字的可视性，同时又不妨碍重要的视觉内容。

文章认为这种方式不会增加额外的复杂度，并且可移植性良好。直接在每一帧的图像上添加编号，对于本来就具有良好的视频内容理解能力的大语言模型来说，相当于直接获得了视频的时间信息，因此，事件定位只是一件顺手的事情。

概念示意图如下：![概念示意图](https://pic1.imgdb.cn/item/6831610958cb8da5c80b519f.png)



原文总结贡献如下：

1. 我们介绍的 *NumPro* 是一种新颖的方法，它通过在视频帧上叠加帧号来增强 *VidLLM* 的视频时间定位（*VTG* ）能力，使时间定位就像翻转漫画中的数字面板一样直观。
2. 通过实验研究，我们找到了合适的 *NumPro* 设计（字体大小、颜色和位置），既能确保模型的高可探测性，又能将对原始视频内容的干扰降到最低。
3. 我们对 *NumPro* 在无训练和微调情况下的标准 *VTG* 基准和指标进行了全面评估，证明了它在各种模型和数据集上的有效性。

# 3.实现流程

下图展示了文章提出方法的架构图。架构图中包含两种设置，一种是无训练模式，一种是微调模式。


![模型架构图](https://pic1.imgdb.cn/item/68316cdc58cb8da5c80b8492.png)

# 4.实现细节

这个文章的实验总体来说就是在原来模型的基础上，处理输入视频，让输入的视频内容上具有叠加的帧编号。所以其实文章也没有特别的设计架构，文章所做的也就是找到性能最好的标记方式；这个性能最好的判别方式，就是叠加了之后，模型是否可以正确识别数字，另外不影响模型对齐文本和视频内容的效果，这个具体怎么实施的可以参考原文。（文章针对这个数字生成训练的示意图如下）
![数字生成训练](https://pic1.imgdb.cn/item/68316dcc58cb8da5c80b84db.png)

# 5.模型性能

从这个实验效果看，无训练设置是可以提升模型性能的，但是辅以微调，模型的时间定位性能又显著提升。说明模型在处理同类型的特征还是效果更好。

![性能图1](https://pic1.imgdb.cn/item/68316e0658cb8da5c80b84eb.png)
![性能图2](https://pic1.imgdb.cn/item/68316f0c58cb8da5c80b858b.png)

# 6.改进/挑战/问题/想法

* **想法**：这个文章的这种思路，也就是认为模型在处理同类型的特征时，效果会更好。这也是我看的上一篇图像分割文章，也是将文本转换成了一些列与文本相关的图像，从而只进行同类型特征之间的匹配或者对齐等等。说明虽然多模态是一种趋势，但是可能还是同类型的特征，模型处理起来更得心应手。

