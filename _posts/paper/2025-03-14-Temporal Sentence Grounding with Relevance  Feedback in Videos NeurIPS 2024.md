---
layout: post
title: 'Temporal Sentence Grounding with Relevance  Feedback in Videos NeurIPS 2024😊'
subtitle: '具有视频相关性反馈的时间句子定位'
date: 2025-03-14
author: Sun
cover: 'https://pic1.imgdb.cn/item/67d244af88c538a9b5bc3d05.png'
tags: 论文阅读
---

> [Temporal Sentence Grounding with Relevance  Feedback in Videos](https://proceedings.neurips.cc/paper_files/paper/2024/hash/4b96695d9885f038110b8b16ef50e882-Abstract-Conference.html)
> > 💐💐提供代码
> 
> 1. ​浙江工商大学
> 2. 浙江省大数据与未来电子商务技术重点实验室
> 3. 北京大学
> 4. 华中科技大学
> 5. 中国科技大学
> 6. 合肥科技大学

# 1.文章针对痛点

这篇文章关注的是与前面的一篇文章关注的是同样的内容，而且这两篇论文的作者也有重合，感觉可能是一个团队吧。

这篇文章认为在传统的时间句子定位任务中，**没有考虑句子描述的内容是否真的与视频相关**，可能存在句子描述的内容与视频无关，但是模型仍然给出了对应的时间范围，出现了错误定位问题。

# 2.主要贡献

因此，为了解决上面的问题，文章提出了一种新的任务，**时间句子定位-相关性反馈（*TSG-RF* ）**，并提出解决该任务的新的模型架构，**相关性感知的时间句子定位**。该模型促进相关性判别和视频片段定位之间的相互增强，通过共享知识，实现面向两个任务的统一且高效的方法。

对于相关性判别任务，文章提出以两种不同的粒度：**细粒度和粗粒度，首先探索文本和视频之间的部分语义相关性的测量**。具体来说，1️⃣文章采用多实例学习概念来捕获细粒度部分相关性。也就是把整个视频视为一个袋，每一帧视为一个实例；如果至少包含一个前景帧，则视为视频与文本相关；如果帧全部都是背景帧或不相关，则视为视频与文本不相关。2️⃣同时，文章考虑到单个视频帧的语义不完整性，提出使用粗粒度来嘘唏全局视频级语义和全部查询文本之间的相关性。最后使用一个多粒度相关性判别器整合上述两种粒度得到最后的相关性分数。

具有了判别性分数后，后面就是对于相关的就正常进行时间句子定位，而不相关的就拒绝，即不进行时间句子定位。

原文将文章工作总结如下：

1. 正式化了一项新颖的*TSG* 任务，以更灵活的探索视频中片段定位，即在视频中具有相关反馈（*TSG-RF* ）的时间句子接地，这将用户指定的*TSG* 推进到更实际的应用程序。
2. 针对*TSG-RF* 任务，我们提出了一种新颖的关系感知的时间句子定位（*RaTSG* ）网络，该网络主要取决于多粒性相关判别器和相关性感知的片段模块。设计了多个相关性判别器，以根据查询文本和视频之间的细粒度和粗粒相关性来预测相关性反馈，以及相关性感知的片段定位模块选择性地预测片段定位的开始和最终边界。
3. 为了促进*TSG-RF* 任务的评估，我们重建了两个常用的*TSG* 数据集并建立适当的性能评估指标以满足*TSG-RF* 的设置。对这些重建数据集进行的广泛实验证明了所提出的模型的有效性。

# 3.实现流程

一样，还是先看一下原文展示的模型架构图：![模型架构图](https://pic1.imgdb.cn/item/67d262a188c538a9b5bc61cd.png)

文章所提出的方法整体架构是相对比较简单的，也就是先各自提取特征，然后做一下特征增强；之后就是使用多粒度相关性判别器来判断，文本是否与视频是相关的，根据判断结果在决定后续步骤；如果判断结果是相关的，那么就继续进行相关性感知片段定位；如果不相关就不进行定位。

# 4.实现细节

* **文本特征和视频特征的预处理** ：这部分就是比较简单，先使用预训练的模型提取文本和视频特征；之后，视频特征使用文本引导的增强模块增强视频特征；而文本特征使用自注意力模块实现特征增强。
* **多粒度相关性判别器**：这个模块分为了**细粒度相关性判别器和粗粒度相关性判别器**，前者是衡量句子级文本和帧级视觉语义之间相关性，后者是衡量句子级文本和视频级视觉语义相关性。1️⃣<mark>细粒度相关性判别器</mark>：首先使用一个前景检测器来学习文本和每个视频帧之间的相关性。具体来说，把融合后的文本-视频特征丢尽一个全连接层来预测查询到帧之间的相似性分数；之后，这个分数被投影到0到1之间，这个结果就是**前景帧的预测分数序列**，这一个分数表明了该帧属于前景的可能性。而为了获得细粒度相关性，文章使用多实例学习。也就是将整个视频视为袋，而将每一帧视为实例；前面获得的前景预测分数系列就是**实例分数**，为了获得**相关性分数**，文章将实例分数应用最大池化转化为袋分数，也就是相关性分数，记为$$score_{f_g}$$。2️⃣<mark>视频级相关性判别器</mark>：除了捕获帧级别的相关性分数，文章也尝试从信息更全面的视频级感知片段相关性。而为了生成这个相关性分数，**需要将所有查询相关的逐帧特征聚合为一个全局特征，再检测与与子文本的语义相关性**。具体来说，就是先 获得全局视频特征；之后，融合视频全局特征与句子级文本特征，从而获得视频级相关性信号向量$$g$$；最后，将这个向量输入到一个全连接层中获得最后的相关性分数。<mark>最后将这两个分数取平均，得到最后的多层相关性预测。</mark>
* **相关性感知片段定位**：该模块的目的是涉及一个灵活的片段定位模块，有选择的预测目标片段的开始和结束时间边界。因此，**文章在传统方法的基础上引入了一个相关性感知片段定位模块**。具体来说，就是在**每一个视频特征序列上加一个特殊的*token***（索引为0），这个*token* 不包含定位结果，只是表明查询文本与给定视频中的任何开始和结束边界都不对齐。最后文章选取将前面的视频级相关性信号向量$$g$$作为这个*token*。这部分损失如下所示。

$$
L_{boundary}=-\frac{1}{2}(\sum Y_s\log(P_s)+\sum Y_e\log(P_e)),
$$

前面的相关性计算都采用的二分类交叉熵损失，所以最后这个网络的损失函数如下。

$$
L_{total}=L_{boundary}+\beta L_{frame}+\gamma L_{video},
$$


# 5.模型性能

由于这篇文章是自己提出来的任务，所以在设计网络架构之外，也重构了数据集，引入了不相关查询。

实验性能效果对比图：![效果对比图1](https://pic1.imgdb.cn/item/67d3bddb88c538a9b5bcf11e.png)

# 6.改进/挑战/问题/想法

* **想法**：其实，这篇文章的思路是很简单的，设计的架构看起来也不太难的样子。相比较这个团队的另外一篇文章，我觉得这个要更易懂一点。但是这个论文本身是不太难的。<mark>另外，虽然这两篇文章想要解决的任务是一样的，都是为了解决不相关查询的问题，只不过解决方法设计不一样；但是个人认为本篇文章的思路架构要相对简单，但是由于两篇文章所作实验不尽相同，所以没法完全比较，但是从交叉部分来看，这篇文章的效果要好一点。不过MM2024那篇文章没有提到关于重构数据集，不知道会不会是重构数据集之后可能会有一定的影响。

