---
layout: post
title: '零碎知识记录'
date: 2024-12-10
author: Sun
tags: 个人杂记
---

# 一些知识记录

> 写在开头：因为有的一些问题其实网上找不到答案，所以一些理解和记录是结合chatgpt得到的。可能有些地方有一些错误。

### 目录：

* [什么是非最大抑制（*NMS* ）](#008)
* [怎么理解基于骨架的行为识别中，使用*CNN* 或*RNN* 提取的伪图像](#007)
* [怎么理解单目（*monocular*）*2D* 图像](#006)
* [怎么理解图像分类中的*TOP-1* 和*TOP-5*](#005)
* [怎么理解瓶颈结构](#004)
* [怎么理解论文中提到的*clip-level representations*](#001)
* [怎么理解计算机视觉中的*tube*](#002)
* [怎么理解*patch* 和*token*](#003)

---

* <a id="008">*什么是非最大抑制（*NMS* ）*</a>：是计算机视觉中常用于目标检测任务的一种后处理技术，旨在从多个候选框中筛选出最合适的框，去除冗余的、重叠度过高的候选框，保留预测最准确的目标位置。

---

* <a id="007">*怎么理解基于骨架的行为识别中，使用CNN或RNN提取的伪图像*</a>：使用 **伪图像**是一种将骨架序列数据转化为视觉图像形式的创新方法。这种方法的核心是将骨架点的信息编码为二维图像结构，以便使用擅长处理视觉数据的 **CNN（卷积神经网络）** 或 **RNN（循环神经网络）** 提取特征。

---

* <a id="006">*怎么理解单目（*monocular*）*2D* 图像</a>：即使用单个摄像头拍摄的二维平面图像，不具备深度信息。

---

* <a id="005">*怎么理解图像分类中的TOP-1和TOP-5*</a>：一般在图像分类中，*Top-1 error-rate* 就是使用预测结果（模型预测率最高的那个）和正确结果进行对比，如果相同则表示预测正确！*Top-5 error-rate*表示模型预测的概率最高的五个类别中，是否包含实际的标签。如果这五个类别中有一个与真实类别一致，就算正确。

---

* <a id="004">*怎么理解瓶颈结构*</a>：通常指在神经网络中用于减少模型参数和计算量的一种设计模式。通过使用较小的隐藏层或卷积层来降低输入和输出之间的维度，从而减少信息的流动，但仍然保持模型的表达能力。可以简单理解为，**是通道数的变化，即原通道数先减少，后增大到原来的大小**，用瓶颈来抽象形容。

---

* <a id="001">*怎么理解论文中提到的clip-level representations* </a>：根据论文中的相关图描述，可以看到*clip-level representations* 是由一系列*representations* 转化生成的。因此，可以简单理解为是将多帧的特征组合生成了一个更具代表性的特征向量。

---

* <a id="002">*怎么理解计算机视觉中的tube*</a> ："*tube* " 通常指的是一种表示方式，用于描述在视频序列中随时间变化的物体或目标的空间和时间特征。*tube* 由一系列连续帧中的目标边界框（*bounding box*）组成，形成一个三维结构。这个结构的两个空间维度代表图像中的位置，而第三个维度表示时间。因此在*CVPR2024 FineSports* 数据集那篇论文中，作者提出了一组可学习的视频动作*tube* 查询，这个模块也是符合论文工作的（论文的工作之一就是要得到动作的时空位置）。

---

* <a id="003">*在计算机视觉中，怎么理解patch 和token*</a> ：首先要认识到的是，*patch* 可以被展平为 *token* 进行处理（也可以理解成*token* 就是*patch* 的一种表示形式，或者说*patch* 是生成*token* 的基本单位）。在图像输入中，*patch* 往往就是图像局部区域块；在视频输入中，*patch* 其实就是在图像局部区域块上加上了时间维度。总的来说，就是输入会被分解成*patches*，然后每个*patch* 被映射为一个*token*。

